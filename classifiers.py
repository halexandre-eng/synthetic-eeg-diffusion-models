"""
Classification of Original and Synthetic EEG Data
Applies ML classifiers (Logistic Regression, KNN, CNN, U-Net) to compare the classification performance
on original and synthetic EEG signals generated by diffusion and cWGAN-GP models.

"""

import pandas as pd
import numpy as np
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import (
    accuracy_score, confusion_matrix, precision_score, recall_score, f1_score
)
import tensorflow as tf
from tensorflow.keras.models import Sequential, Model
from tensorflow.keras.layers import (
    Dense, Conv1D, MaxPooling1D, Flatten, Input,
    UpSampling1D, concatenate, ZeroPadding1D, Cropping1D
)
from tensorflow.keras.utils import to_categorical

class EEGDataLoader:
    def __init__(self, original_file, synthetic_file, label_column='label'):
        self.original_file = original_file
        self.synthetic_file = synthetic_file
        self.label_column = label_column

    def load_data(self):
        df_original = pd.read_csv(self.original_file)
        df_synthetic = pd.read_csv(self.synthetic_file, sep=';', decimal=',', thousands='.')
        return df_original.dropna(), df_synthetic.dropna()

    def prepare_features_and_labels(self, df):
        X = df.drop(columns=[self.label_column])
        y = df[self.label_column]
        return X, y

class EEGClassifier:
    def __init__(self, classifier, classifier_name):
        self.classifier = classifier
        self.classifier_name = classifier_name
        self.scaler = StandardScaler()
        self.is_keras_model = isinstance(classifier, tf.keras.Model)

    def train(self, X_train, y_train):
        if self.is_keras_model:
            nsamples, nx, ny = X_train.shape
            X_train_flat = X_train.reshape((nsamples, nx * ny))
            X_train_scaled = self.scaler.fit_transform(X_train_flat)
            X_train_scaled = X_train_scaled.reshape((nsamples, nx, ny))
            num_classes = len(np.unique(y_train))
            y_train_categorical = to_categorical(y_train, num_classes=num_classes)
            self.classifier.compile(
                optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy']
            )
            self.classifier.fit(
                X_train_scaled, y_train_categorical, epochs=10, batch_size=32, verbose=0
            )
        else:
            X_train_scaled = self.scaler.fit_transform(X_train)
            self.classifier.fit(X_train_scaled, y_train)

    def predict(self, X_test):
        if self.is_keras_model:
            nsamples, nx, ny = X_test.shape
            X_test_flat = X_test.reshape((nsamples, nx * ny))
            X_test_scaled = self.scaler.transform(X_test_flat)
            X_test_scaled = X_test_scaled.reshape((nsamples, nx, ny))
            y_pred_proba = self.classifier.predict(X_test_scaled)
            return np.argmax(y_pred_proba, axis=1)
        else:
            X_test_scaled = self.scaler.transform(X_test)
            return self.classifier.predict(X_test_scaled)

    def evaluate(self, X_test, y_test):
        y_pred = self.predict(X_test)
        return {
            'Acurácia': accuracy_score(y_test, y_pred),
            'Precisão': precision_score(y_test, y_pred, average='weighted', zero_division=0),
            'Recall': recall_score(y_test, y_pred, average='weighted', zero_division=0),
            'F1-Score': f1_score(y_test, y_pred, average='weighted', zero_division=0),
            'Matriz de Confusão': confusion_matrix(y_test, y_pred)
        }

def create_cnn_model(input_shape, num_classes):
    model = Sequential([
        Conv1D(64, 3, activation='relu', padding='same', input_shape=input_shape),
        MaxPooling1D(2, padding='same'),
        Conv1D(128, 3, activation='relu', padding='same'),
        MaxPooling1D(2, padding='same'),
        Flatten(),
        Dense(100, activation='relu'),
        Dense(num_classes, activation='softmax')
    ])
    return model

def create_unet_model(input_shape, num_classes):
    inputs = Input(shape=input_shape)
    conv1 = Conv1D(64, 3, activation='relu', padding='same')(inputs)
    pool1 = MaxPooling1D(2, padding='same')(conv1)
    conv2 = Conv1D(128, 3, activation='relu', padding='same')(pool1)
    pool2 = MaxPooling1D(2, padding='same')(conv2)
    conv3 = Conv1D(256, 3, activation='relu', padding='same')(pool2)
    up4 = UpSampling1D(2)(conv3)
    if conv2.shape[1] != up4.shape[1]:
        up4 = ZeroPadding1D(padding=(0, conv2.shape[1] - up4.shape[1]))(up4) if conv2.shape[1] > up4.shape[1] else Cropping1D(cropping=(0, up4.shape[1] - conv2.shape[1]))(up4)
    merge4 = concatenate([conv2, up4], axis=-1)
    conv4 = Conv1D(128, 3, activation='relu', padding='same')(merge4)
    up5 = UpSampling1D(2)(conv4)
    if conv1.shape[1] != up5.shape[1]:
        up5 = ZeroPadding1D(padding=(0, conv1.shape[1] - up5.shape[1]))(up5) if conv1.shape[1] > up5.shape[1] else Cropping1D(cropping=(0, up5.shape[1] - conv1.shape[1]))(up5)
    merge5 = concatenate([conv1, up5], axis=-1)
    conv5 = Conv1D(64, 3, activation='relu', padding='same')(merge5)
    flat = Flatten()(conv5)
    outputs = Dense(num_classes, activation='softmax')(flat)
    return Model(inputs=inputs, outputs=outputs)
